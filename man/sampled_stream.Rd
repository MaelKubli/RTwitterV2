% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sampled_stream.R
\name{sampled_stream}
\alias{sampled_stream}
\title{This function allows you to collect tweets from the 1 \% sampled stream from twitter}
\usage{
sampled_stream(
  token = "",
  timeout = 0,
  backfill = 0,
  file_name = NULL,
  verbose = T,
  parse = F
)
}
\arguments{
\item{token}{string of the bearer token from your personal twitter API access}

\item{timeout}{numeric scalar specifying amount of time, in seconds, to leave connection open while streaming/capturing tweets. By default, this is set to 30 seconds. The maximum duration for an open stream is set to 300 seconds to avoid large json files. .}

\item{backfill}{By passing this parameter, you can request up to five (5) minutes worth of streaming data that you might have missed during a disconnection to be delivered to you upon re-connection. The back filled Tweets will automatically flow through the reconnected stream, with older Tweets generally being delivered before any newly matching Tweets. You must include a whole number between 1 and 5 as the value to this parameter. This feature will deliver duplicate Tweets, meaning that if you were disconnected for 90 seconds, and you requested two minutes of backfill, you will receive 30 seconds worth of duplicate Tweets. Due to this, you should make sure your system is tolerant of duplicate data. This feature is currently only available to those that have been approved for Academic Research access. To learn more about this access level, please visit our section on Academic Research.}

\item{file_name}{character with name of file. By default, a temporary file is created, tweets are parsed and returned to parent environment, and the temporary file is deleted.}

\item{verbose}{logical, indicating whether or not to include output processing/retrieval messages.}

\item{parse}{logical,indicating whether to return parsed data. By default, parse = FALSE, this function does the parsing for you. However, for larger streams, or for automated scripts designed to continuously collect data, this should be set to false as the parsing process can eat up processing resources and time.}
}
\value{
a data frame
}
\description{
This function allows you to collect tweets from the 1 \% sampled stream from twitter
}
\examples{
\dontrun{
sampled_stream(Token = your_token, timeout = 60, backfill = 0,
               file_name = "test_stream_2.json", verbose = T,
               parse = F)

tdf <- sampled_stream(Token = your_token, timeout = 60, backfill = 0,
                      verbose = T, parse = T)
}

}
